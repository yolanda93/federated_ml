{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "twelve-vancouver",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import torch as torch\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "developmental-stopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jake has: {52973500771: <Plan Plan id:52973500771 owner:jake Tags: #fss_eq_plan_1 built>\n",
      ", 99696909270: <Plan Plan id:99696909270 owner:jake Tags: #fss_eq_plan_2 built>\n",
      ", 80807883839: <Plan Plan id:80807883839 owner:jake Tags: #fss_comp_plan_1 built>\n",
      ", 911630716: <Plan Plan id:911630716 owner:jake Tags: #fss_comp_plan_2 built>\n",
      ", 90045197714: <Plan Plan id:90045197714 owner:jake Tags: #xor_add_1 built>\n",
      ", 51137915516: <Plan Plan id:51137915516 owner:jake Tags: #xor_add_2 built>\n",
      ", 81187714074: <Plan Plan id:81187714074 owner:jake Tags: #fss_eq_plan_1 built>\n",
      ", 88382600198: <Plan Plan id:88382600198 owner:jake Tags: #fss_eq_plan_2 built>\n",
      ", 72296214479: <Plan Plan id:72296214479 owner:jake Tags: #fss_comp_plan_1 built>\n",
      ", 59728129458: <Plan Plan id:59728129458 owner:jake Tags: #fss_comp_plan_2 built>\n",
      ", 97167328842: <Plan Plan id:97167328842 owner:jake Tags: #xor_add_1 built>\n",
      ", 93791304854: <Plan Plan id:93791304854 owner:jake Tags: #xor_add_2 built>\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "jake = sy.VirtualWorker(hook, id=\"jake\")\n",
    "print(\"Jake has: \" + str(jake._objects))\n",
    "\n",
    "john = sy.VirtualWorker(hook, id=\"john\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "owned-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.5, )),\n",
    "])\n",
    "\n",
    "train_set = datasets.MNIST(\n",
    "    \"~/.pytorch/MNIST_data/\", train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(\n",
    "    \"~/.pytorch/MNIST_data/\", train=False, download=True, transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    train_set.federate((jake, john)), batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "registered-pressure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hearing-bradford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "persistent-column",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /root/.pytorch/MNIST_data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(0.5,))\n",
       "           )"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "excess-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Model()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "boring-fossil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 [    0/60032 (  0%)]\tLoss: 2.353447\n",
      "Epoch:  1 [ 6400/60032 ( 11%)]\tLoss: 1.348159\n",
      "Epoch:  1 [12800/60032 ( 21%)]\tLoss: 0.839848\n",
      "Epoch:  1 [19200/60032 ( 32%)]\tLoss: 0.701301\n",
      "Epoch:  1 [25600/60032 ( 43%)]\tLoss: 0.544994\n",
      "Epoch:  1 [32000/60032 ( 53%)]\tLoss: 0.552950\n",
      "Epoch:  1 [38400/60032 ( 64%)]\tLoss: 0.586103\n",
      "Epoch:  1 [44800/60032 ( 75%)]\tLoss: 0.486136\n",
      "Epoch:  1 [51200/60032 ( 85%)]\tLoss: 0.324459\n",
      "Epoch:  1 [57600/60032 ( 96%)]\tLoss: 0.410363\n",
      "Epoch:  2 [    0/60032 (  0%)]\tLoss: 0.478832\n",
      "Epoch:  2 [ 6400/60032 ( 11%)]\tLoss: 0.545559\n",
      "Epoch:  2 [12800/60032 ( 21%)]\tLoss: 0.277177\n",
      "Epoch:  2 [19200/60032 ( 32%)]\tLoss: 0.213412\n",
      "Epoch:  2 [25600/60032 ( 43%)]\tLoss: 0.242448\n",
      "Epoch:  2 [32000/60032 ( 53%)]\tLoss: 0.441177\n",
      "Epoch:  2 [38400/60032 ( 64%)]\tLoss: 0.506062\n",
      "Epoch:  2 [44800/60032 ( 75%)]\tLoss: 0.258631\n",
      "Epoch:  2 [51200/60032 ( 85%)]\tLoss: 0.303522\n",
      "Epoch:  2 [57600/60032 ( 96%)]\tLoss: 0.466407\n",
      "Epoch:  3 [    0/60032 (  0%)]\tLoss: 0.329046\n",
      "Epoch:  3 [ 6400/60032 ( 11%)]\tLoss: 0.225281\n",
      "Epoch:  3 [12800/60032 ( 21%)]\tLoss: 0.326261\n",
      "Epoch:  3 [19200/60032 ( 32%)]\tLoss: 0.342851\n",
      "Epoch:  3 [25600/60032 ( 43%)]\tLoss: 0.408007\n",
      "Epoch:  3 [32000/60032 ( 53%)]\tLoss: 0.246408\n",
      "Epoch:  3 [38400/60032 ( 64%)]\tLoss: 0.325176\n",
      "Epoch:  3 [44800/60032 ( 75%)]\tLoss: 0.262218\n",
      "Epoch:  3 [51200/60032 ( 85%)]\tLoss: 0.328136\n",
      "Epoch:  3 [57600/60032 ( 96%)]\tLoss: 0.284240\n",
      "Epoch:  4 [    0/60032 (  0%)]\tLoss: 0.156267\n",
      "Epoch:  4 [ 6400/60032 ( 11%)]\tLoss: 0.209224\n",
      "Epoch:  4 [12800/60032 ( 21%)]\tLoss: 0.208384\n",
      "Epoch:  4 [19200/60032 ( 32%)]\tLoss: 0.498551\n",
      "Epoch:  4 [25600/60032 ( 43%)]\tLoss: 0.134493\n",
      "Epoch:  4 [32000/60032 ( 53%)]\tLoss: 0.372619\n",
      "Epoch:  4 [38400/60032 ( 64%)]\tLoss: 0.291413\n",
      "Epoch:  4 [44800/60032 ( 75%)]\tLoss: 0.259284\n",
      "Epoch:  4 [51200/60032 ( 85%)]\tLoss: 0.404511\n",
      "Epoch:  4 [57600/60032 ( 96%)]\tLoss: 0.464566\n",
      "Epoch:  5 [    0/60032 (  0%)]\tLoss: 0.335219\n",
      "Epoch:  5 [ 6400/60032 ( 11%)]\tLoss: 0.312748\n",
      "Epoch:  5 [12800/60032 ( 21%)]\tLoss: 0.223564\n",
      "Epoch:  5 [19200/60032 ( 32%)]\tLoss: 0.354690\n",
      "Epoch:  5 [25600/60032 ( 43%)]\tLoss: 0.179445\n",
      "Epoch:  5 [32000/60032 ( 53%)]\tLoss: 0.276692\n",
      "Epoch:  5 [38400/60032 ( 64%)]\tLoss: 0.222795\n",
      "Epoch:  5 [44800/60032 ( 75%)]\tLoss: 0.248491\n",
      "Epoch:  5 [51200/60032 ( 85%)]\tLoss: 0.316773\n",
      "Epoch:  5 [57600/60032 ( 96%)]\tLoss: 0.240378\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 5):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(federated_train_loader):\n",
    "        # send the model to the client device where the data is present\n",
    "        model.send(data.location)\n",
    "        # training the model\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # get back the improved model\n",
    "        model.get()\n",
    "        if batch_idx % 100 == 0: # print results each 100 iterations\n",
    "            # get back the loss\n",
    "            loss = loss.get()\n",
    "            print('Epoch: {:2d} [{:5d}/{:5d} ({:3.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1,\n",
    "                batch_idx * 64,\n",
    "                len(federated_train_loader) * 64,\n",
    "                100. * batch_idx / len(federated_train_loader),\n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cooperative-credits",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2492, Accuracy: 9281/10000 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(\n",
    "            output, target, reduction='sum').item()\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.argmax(1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss,\n",
    "    correct,\n",
    "    len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-conservation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
